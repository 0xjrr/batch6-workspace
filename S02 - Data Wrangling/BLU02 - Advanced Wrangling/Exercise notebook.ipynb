{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b66f2958",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3bf24e7ba2c45b1c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# BLU02 - Exercises Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd525da6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bebba7f87f4f151b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import hashlib # for grading\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b2b87c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a23783765364606a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1 Read the Programs data (graded)\n",
    "\n",
    "In this first exercise, we aim to create a single dataframe, combining all programs from all seasons.\n",
    "\n",
    "With a caveat though: **we want to include seasons from the year 1950 onwards**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e539f29e",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e16abeb47fc4ea37",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def read_season(folder_path, file_name):\n",
    "    path = os.path.join(folder_path, file_name)\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def read_programs(folder_path):\n",
    "    files = os.listdir(folder_path)\n",
    "    # Create a list with the name of all files containing programs from\n",
    "    # 1950 inclusive and onwards (just the filename, no complete path.)\n",
    "    # files_from_1950: List[str] = ...\n",
    "    # YOUR CODE HERE\n",
    "    files_from_1950 = [file for file in os.listdir(folder_path) if int(file[0:4])>=1950 ]\n",
    "    # raise NotImplementedError()\n",
    "    # Create a list with the dataframes\n",
    "    # seasons: List[pd.DataFrame] = ...\n",
    "    seasons = [pd.read_csv(os.path.join(folder_path, file)) for file in files_from_1950]\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    # Use pd.concat to create a single dataframe.\n",
    "    # programs: pd.DataFrame = ...\n",
    "    # YOUR CODE HERE\n",
    "    programs = pd.concat(seasons, axis=0, ignore_index=True)\n",
    "    # raise NotImplementedError()\n",
    "    # Drop the column GUID.\n",
    "    # programs = ...\n",
    "    # YOUR CODE HERE\n",
    "    programs = programs.drop(\"GUID\",axis=1)\n",
    "    # raise NotImplementedError()\n",
    "    ## Remove Duplicated lines.\n",
    "    # YOUR CODE HERE\n",
    "    programs = programs.drop_duplicates()\n",
    "    # raise NotImplementedError()\n",
    "    # Set the index to be the column ProgramID\n",
    "    # YOUR CODE HERE\n",
    "    programs = programs.set_index(\"ProgramID\")\n",
    "\n",
    "    # raise NotImplementedError()\n",
    "    return programs\n",
    "\n",
    "programs = read_programs(os.path.join('data', 'programs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d5b3ffb",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-2656708135a5a5e4",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert programs['Season'].min() == '1950-51'\n",
    "assert programs['Season'].max() == '2016-17'\n",
    "assert programs.index.name == 'ProgramID'\n",
    "assert programs.shape == (7341, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31920670",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3383047fa18f453e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2 Read the Concerts data (graded)\n",
    "\n",
    "Although we list all transformations step-by-step for the sake of clarity, we expect you to use method chaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0f86c9d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e228c2d82463c6b4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def make_concerts(file_path): \n",
    "    # Read concerts data and drop the GUID column.\n",
    "    # concerts: pd.DataFrame = ...\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    # Remember to_datetime? We need it here. We need to parse the columns Date and \n",
    "    # Time. Use pd.to_datetime(...).dt.date for the Date. \n",
    "    # then use the same logic to create the column Hour and Minute from Time column.\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    ## Remove Duplicated lines.\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    ## Remove all lines with empty Time column. Then also drop the Time column.\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    concerts: pd.DataFrame = (pd.read_csv(file_path)\n",
    "                                .dropna(subset=\"Time\")\n",
    "                                .assign(Date = lambda x: pd.to_datetime(x['Date']).dt.date,\n",
    "                                        Hour = lambda x: pd.to_datetime(x['Time']).dt.hour,\n",
    "                                        Minute = lambda x: pd.to_datetime(x['Time']).dt.minute\n",
    "                                    )\n",
    "                                .drop(['Time', 'GUID'], axis=1)\n",
    "                                .drop_duplicates()\n",
    "                                )\n",
    "    \n",
    "    return concerts\n",
    "\n",
    "concerts = make_concerts(os.path.join('data','concerts.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52e0b5f0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3d21007e725ab889",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert concerts.shape == (20812, 8)\n",
    "assert concerts.Date.min() == datetime.date(1842, 12, 7)\n",
    "assert concerts.Date.max() == datetime.date(2017, 7, 7)\n",
    "assert concerts.Date.max() == datetime.date(2017, 7, 7)\n",
    "assert concerts['Hour'].mode().values[0] == 20\n",
    "assert concerts['Minute'].mode().values[0] == 0\n",
    "assert list(concerts.iloc[1537][['Hour', 'Minute']].values) == [20,30]\n",
    "assert list(concerts.iloc[1201][['Hour', 'Minute']].values) == [20,15]\n",
    "assert set(concerts.columns) == set([\n",
    "    'ProgramID', 'ConcertID', 'EventType', 'Location', 'Venue', 'Date', 'Hour', 'Minute'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d6c904",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2ae195e6dd100fc5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3 Combine Programs and Concerts data (graded)\n",
    "\n",
    "Let's combine both dataframes into a single dataset, using an inner join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "61a56101",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a65f1464b4525a8b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Remember that you want to join on the index of one of the dataframes.\n",
    "# Join only the concerts with valid ProgramIDs\n",
    "# nyp = ...\n",
    "# YOUR CODE HERE\n",
    "nyp: pd.DataFrame = pd.merge(programs, concerts, how='inner', on='ProgramID')\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "26483891",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ac9aef3d5251e36c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert nyp.shape == (12943, 10)\n",
    "assert set(nyp.columns) == set([\n",
    "    'ProgramID', 'ConcertID', 'EventType', 'Location', 'Venue',\n",
    "    'Date', 'Hour', 'Minute', 'Orchestra', 'Season'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71271ecf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1fd4cd11d5139889",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 4 Read Works and Soloists data (graded)\n",
    "\n",
    "We will read the two remaining pieces of data. \n",
    "\n",
    "Again, albeit the step-by-step description, we encourage you to use method chaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cb533fb6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-503e208490ff38e0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def read_works(file_path):\n",
    "    # Read the works data.\n",
    "    # works: pd.DataFrame = ...\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    # Remove the Intervals (attention to the values in the isInterval column).\n",
    "    # works: pd.DataFrame = ...\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    # Select the columns ProgramID, WorkID, ComposerName, WorkTitle, Movement and ConductorName.\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    ## Remove Duplicated lines.\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    ## Remove all lines with empty Movement column.\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    works: pd.DataFrame = (pd.read_csv(file_path)\n",
    "                            .pipe(lambda df: df[~df['isInterval']])\n",
    "                            .filter(items=['ProgramID', 'WorkID', 'ComposerName', 'WorkTitle', 'Movement', 'ConductorName'])\n",
    "                            .drop_duplicates()\n",
    "                            .dropna(subset='Movement')\n",
    "                            )\n",
    "    return works\n",
    "\n",
    "\n",
    "def read_soloists(file_path):\n",
    "    # Read the soloists data and drop GUID and MovementID Columns\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    ## Remove Duplicated lines.\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    soloists: pd.DataFrame = (pd.read_csv(file_path)\n",
    "                                .drop(['GUID', 'MovementID'], axis=1)\n",
    "                                .drop_duplicates()\n",
    "                                )\n",
    "    return soloists\n",
    "\n",
    "\n",
    "works = read_works('data/works.csv')\n",
    "soloists = read_soloists('data/soloists.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "11f60f07",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b8389314995f18ea",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert works.shape == (24320, 6)\n",
    "assert set(works.columns) == set([\n",
    "    'ProgramID', 'WorkID', 'ComposerName', 'WorkTitle', 'Movement', 'ConductorName'\n",
    "])\n",
    "\n",
    "assert soloists.shape == (50292, 5)\n",
    "assert set(soloists.columns) == set([\n",
    "   'ProgramID', 'WorkID', 'SoloistName', 'SoloistInstrument', 'SoloistRole'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839081fe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c16e4e26e68cd019",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 5 Combine Works and Soloists (graded)\n",
    "\n",
    "Like we did for Programs and Concerts, now we combine Works and Soloists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dfae5297",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-08d9a086cc5646cf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Combine both dataframes, again using an inner type of join. An work is identified by the pair\n",
    "# ProgramId, WorkID\n",
    "# works_and_soloists : pd.DataFrame = ....\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "works_and_soloists : pd.DataFrame = pd.merge(works, soloists, how='inner', on=['ProgramID', 'WorkID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7184d4cd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4d9f103dfffd311b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert works_and_soloists.shape == (23578, 9)\n",
    "assert set(works_and_soloists.columns) == set(\n",
    "    [\n",
    "        'ProgramID', 'WorkID', 'ComposerName', 'WorkTitle', 'Movement',\n",
    "        'ConductorName', 'SoloistName', 'SoloistInstrument', 'SoloistRole'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cddd282",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ab79800d6e447f1e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 6 Combine everything (graded)\n",
    "\n",
    "The final goal here is to create a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6a4eee72",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ce1f05022e8cd63a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Combine works_and_soloists and nyp into a single dataframe.\n",
    "# You need to figure out the common column shared between the two dataframes\n",
    "# nyp_merged = ...\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "nyp_merged: pd.DataFrame = pd.merge(nyp, works_and_soloists, how='inner', on='ProgramID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "55c7dc60",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ce29fa3aec1c244e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert nyp_merged.shape == (27725, 18)\n",
    "assert set(nyp_merged.columns) == set(\n",
    "    [\n",
    "       'ProgramID', 'ConcertID', 'EventType', 'Location', 'Venue', 'Date',\n",
    "       'Hour', 'Minute', 'Orchestra', 'Season', 'WorkID', 'ComposerName', 'WorkTitle',\n",
    "       'Movement', 'ConductorName', 'SoloistName', 'SoloistInstrument',\n",
    "       'SoloistRole'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73c7125",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4407d9518b0d6e2e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 7 Final transformations (graded)\n",
    "\n",
    "Now, we perform the train-test split.\n",
    "\n",
    "We also perform some final transformations on both datasets:\n",
    "\n",
    "* Include some date features: Year, Month, Day and Weekday\n",
    "* Create a new feature, ComposerLastName from ComposerName column. \n",
    "* Filter out rows with a location that appears less than 10 times in the DataFrame.\n",
    "* Drop ProgramID, ConcertID, WorkID, Date and Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5908fd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ProgramID</th>\n",
       "      <th>Orchestra</th>\n",
       "      <th>Season</th>\n",
       "      <th>ConcertID</th>\n",
       "      <th>EventType</th>\n",
       "      <th>Location</th>\n",
       "      <th>Venue</th>\n",
       "      <th>Date</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Minute</th>\n",
       "      <th>WorkID</th>\n",
       "      <th>ComposerName</th>\n",
       "      <th>WorkTitle</th>\n",
       "      <th>Movement</th>\n",
       "      <th>ConductorName</th>\n",
       "      <th>SoloistName</th>\n",
       "      <th>SoloistInstrument</th>\n",
       "      <th>SoloistRole</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3128</td>\n",
       "      <td>New York Philharmonic</td>\n",
       "      <td>1950-51</td>\n",
       "      <td>0</td>\n",
       "      <td>Special</td>\n",
       "      <td>Manhattan, NY</td>\n",
       "      <td>Roxy Theatre</td>\n",
       "      <td>1950-09-01</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>8476</td>\n",
       "      <td>Puccini,  Giacomo</td>\n",
       "      <td>MADAMA BUTTERFLY</td>\n",
       "      <td>\"Un bel dì vedremo,\" Cio-Cio-San (aria), Act II</td>\n",
       "      <td>Mitropoulos, Dimitri</td>\n",
       "      <td>Farrell, Eileen</td>\n",
       "      <td>Soprano</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3128</td>\n",
       "      <td>New York Philharmonic</td>\n",
       "      <td>1950-51</td>\n",
       "      <td>0</td>\n",
       "      <td>Special</td>\n",
       "      <td>Manhattan, NY</td>\n",
       "      <td>Roxy Theatre</td>\n",
       "      <td>1950-09-01</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4793</td>\n",
       "      <td>Flotow,  Friedrich  Von</td>\n",
       "      <td>MARTHA</td>\n",
       "      <td>\"The Last Rose of Summer,\" (aria)</td>\n",
       "      <td>Mitropoulos, Dimitri</td>\n",
       "      <td>Farrell, Eileen</td>\n",
       "      <td>Soprano</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5692</td>\n",
       "      <td>New York Philharmonic</td>\n",
       "      <td>1950-51</td>\n",
       "      <td>0</td>\n",
       "      <td>Subscription Season</td>\n",
       "      <td>Manhattan, NY</td>\n",
       "      <td>Carnegie Hall</td>\n",
       "      <td>1950-10-19</td>\n",
       "      <td>20</td>\n",
       "      <td>45</td>\n",
       "      <td>50969</td>\n",
       "      <td>Lalo,  Edouard</td>\n",
       "      <td>SYMPHONIE ESPAGNOLE, OP. 21</td>\n",
       "      <td>Allegro non troppo</td>\n",
       "      <td>Mitropoulos, Dimitri</td>\n",
       "      <td>Renardy, Ossy</td>\n",
       "      <td>Violin</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5692</td>\n",
       "      <td>New York Philharmonic</td>\n",
       "      <td>1950-51</td>\n",
       "      <td>0</td>\n",
       "      <td>Subscription Season</td>\n",
       "      <td>Manhattan, NY</td>\n",
       "      <td>Carnegie Hall</td>\n",
       "      <td>1950-10-19</td>\n",
       "      <td>20</td>\n",
       "      <td>45</td>\n",
       "      <td>50969</td>\n",
       "      <td>Lalo,  Edouard</td>\n",
       "      <td>SYMPHONIE ESPAGNOLE, OP. 21</td>\n",
       "      <td>Scherzando: Allegro molto</td>\n",
       "      <td>Mitropoulos, Dimitri</td>\n",
       "      <td>Renardy, Ossy</td>\n",
       "      <td>Violin</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5692</td>\n",
       "      <td>New York Philharmonic</td>\n",
       "      <td>1950-51</td>\n",
       "      <td>0</td>\n",
       "      <td>Subscription Season</td>\n",
       "      <td>Manhattan, NY</td>\n",
       "      <td>Carnegie Hall</td>\n",
       "      <td>1950-10-19</td>\n",
       "      <td>20</td>\n",
       "      <td>45</td>\n",
       "      <td>50969</td>\n",
       "      <td>Lalo,  Edouard</td>\n",
       "      <td>SYMPHONIE ESPAGNOLE, OP. 21</td>\n",
       "      <td>Andante</td>\n",
       "      <td>Mitropoulos, Dimitri</td>\n",
       "      <td>Renardy, Ossy</td>\n",
       "      <td>Violin</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27720</th>\n",
       "      <td>14182</td>\n",
       "      <td>Musicians from the New York Philharmonic</td>\n",
       "      <td>2016-17</td>\n",
       "      <td>0</td>\n",
       "      <td>Parks - Free Indoor Concert</td>\n",
       "      <td>Staten Island, NY</td>\n",
       "      <td>Snug Harbor</td>\n",
       "      <td>2017-06-18</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>9176</td>\n",
       "      <td>Mozart,  Wolfgang  Amadeus</td>\n",
       "      <td>DON GIOVANNI, K.527:  SUITE FOR WINDS (ARR. Tr...</td>\n",
       "      <td>Là ci darem la mano</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spanjer, R. Allen</td>\n",
       "      <td>French Horn</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27721</th>\n",
       "      <td>14136</td>\n",
       "      <td>New York Philharmonic</td>\n",
       "      <td>2016-17</td>\n",
       "      <td>0</td>\n",
       "      <td>Tour - Young People's Concert</td>\n",
       "      <td>Shanghai, CHINA</td>\n",
       "      <td>Shanghai Symphony Hall--Chamber Hall</td>\n",
       "      <td>2017-07-04</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>2877</td>\n",
       "      <td>Dvorak,  Antonín</td>\n",
       "      <td>SYMPHONY NO. 9, E MINOR, OP.95 (FROM THE NEW W...</td>\n",
       "      <td>Mvt. I, Excerpt</td>\n",
       "      <td>Gersen, Joshua</td>\n",
       "      <td>Xu, Weiqin</td>\n",
       "      <td>Baritone</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27722</th>\n",
       "      <td>14136</td>\n",
       "      <td>New York Philharmonic</td>\n",
       "      <td>2016-17</td>\n",
       "      <td>0</td>\n",
       "      <td>Tour - Young People's Concert</td>\n",
       "      <td>Shanghai, CHINA</td>\n",
       "      <td>Shanghai Symphony Hall--Chamber Hall</td>\n",
       "      <td>2017-07-04</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>2877</td>\n",
       "      <td>Dvorak,  Antonín</td>\n",
       "      <td>SYMPHONY NO. 9, E MINOR, OP.95 (FROM THE NEW W...</td>\n",
       "      <td>Mvt. II, Excerpt</td>\n",
       "      <td>Gersen, Joshua</td>\n",
       "      <td>Xu, Weiqin</td>\n",
       "      <td>Baritone</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27723</th>\n",
       "      <td>14136</td>\n",
       "      <td>New York Philharmonic</td>\n",
       "      <td>2016-17</td>\n",
       "      <td>0</td>\n",
       "      <td>Tour - Young People's Concert</td>\n",
       "      <td>Shanghai, CHINA</td>\n",
       "      <td>Shanghai Symphony Hall--Chamber Hall</td>\n",
       "      <td>2017-07-04</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>2877</td>\n",
       "      <td>Dvorak,  Antonín</td>\n",
       "      <td>SYMPHONY NO. 9, E MINOR, OP.95 (FROM THE NEW W...</td>\n",
       "      <td>Mvt. III, Excerpt</td>\n",
       "      <td>Gersen, Joshua</td>\n",
       "      <td>Xu, Weiqin</td>\n",
       "      <td>Baritone</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27724</th>\n",
       "      <td>14136</td>\n",
       "      <td>New York Philharmonic</td>\n",
       "      <td>2016-17</td>\n",
       "      <td>0</td>\n",
       "      <td>Tour - Young People's Concert</td>\n",
       "      <td>Shanghai, CHINA</td>\n",
       "      <td>Shanghai Symphony Hall--Chamber Hall</td>\n",
       "      <td>2017-07-04</td>\n",
       "      <td>19</td>\n",
       "      <td>30</td>\n",
       "      <td>2877</td>\n",
       "      <td>Dvorak,  Antonín</td>\n",
       "      <td>SYMPHONY NO. 9, E MINOR, OP.95 (FROM THE NEW W...</td>\n",
       "      <td>Allegro con fuoco</td>\n",
       "      <td>Gersen, Joshua</td>\n",
       "      <td>Xu, Weiqin</td>\n",
       "      <td>Baritone</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27725 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ProgramID                                 Orchestra   Season  \\\n",
       "0           3128                     New York Philharmonic  1950-51   \n",
       "1           3128                     New York Philharmonic  1950-51   \n",
       "2           5692                     New York Philharmonic  1950-51   \n",
       "3           5692                     New York Philharmonic  1950-51   \n",
       "4           5692                     New York Philharmonic  1950-51   \n",
       "...          ...                                       ...      ...   \n",
       "27720      14182  Musicians from the New York Philharmonic  2016-17   \n",
       "27721      14136                     New York Philharmonic  2016-17   \n",
       "27722      14136                     New York Philharmonic  2016-17   \n",
       "27723      14136                     New York Philharmonic  2016-17   \n",
       "27724      14136                     New York Philharmonic  2016-17   \n",
       "\n",
       "       ConcertID                      EventType           Location  \\\n",
       "0              0                        Special      Manhattan, NY   \n",
       "1              0                        Special      Manhattan, NY   \n",
       "2              0            Subscription Season      Manhattan, NY   \n",
       "3              0            Subscription Season      Manhattan, NY   \n",
       "4              0            Subscription Season      Manhattan, NY   \n",
       "...          ...                            ...                ...   \n",
       "27720          0    Parks - Free Indoor Concert  Staten Island, NY   \n",
       "27721          0  Tour - Young People's Concert    Shanghai, CHINA   \n",
       "27722          0  Tour - Young People's Concert    Shanghai, CHINA   \n",
       "27723          0  Tour - Young People's Concert    Shanghai, CHINA   \n",
       "27724          0  Tour - Young People's Concert    Shanghai, CHINA   \n",
       "\n",
       "                                      Venue        Date  Hour  Minute  WorkID  \\\n",
       "0                              Roxy Theatre  1950-09-01    12       0    8476   \n",
       "1                              Roxy Theatre  1950-09-01    12       0    4793   \n",
       "2                             Carnegie Hall  1950-10-19    20      45   50969   \n",
       "3                             Carnegie Hall  1950-10-19    20      45   50969   \n",
       "4                             Carnegie Hall  1950-10-19    20      45   50969   \n",
       "...                                     ...         ...   ...     ...     ...   \n",
       "27720                           Snug Harbor  2017-06-18    15       0    9176   \n",
       "27721  Shanghai Symphony Hall--Chamber Hall  2017-07-04    19      30    2877   \n",
       "27722  Shanghai Symphony Hall--Chamber Hall  2017-07-04    19      30    2877   \n",
       "27723  Shanghai Symphony Hall--Chamber Hall  2017-07-04    19      30    2877   \n",
       "27724  Shanghai Symphony Hall--Chamber Hall  2017-07-04    19      30    2877   \n",
       "\n",
       "                     ComposerName  \\\n",
       "0               Puccini,  Giacomo   \n",
       "1         Flotow,  Friedrich  Von   \n",
       "2                  Lalo,  Edouard   \n",
       "3                  Lalo,  Edouard   \n",
       "4                  Lalo,  Edouard   \n",
       "...                           ...   \n",
       "27720  Mozart,  Wolfgang  Amadeus   \n",
       "27721            Dvorak,  Antonín   \n",
       "27722            Dvorak,  Antonín   \n",
       "27723            Dvorak,  Antonín   \n",
       "27724            Dvorak,  Antonín   \n",
       "\n",
       "                                               WorkTitle  \\\n",
       "0                                       MADAMA BUTTERFLY   \n",
       "1                                                 MARTHA   \n",
       "2                            SYMPHONIE ESPAGNOLE, OP. 21   \n",
       "3                            SYMPHONIE ESPAGNOLE, OP. 21   \n",
       "4                            SYMPHONIE ESPAGNOLE, OP. 21   \n",
       "...                                                  ...   \n",
       "27720  DON GIOVANNI, K.527:  SUITE FOR WINDS (ARR. Tr...   \n",
       "27721  SYMPHONY NO. 9, E MINOR, OP.95 (FROM THE NEW W...   \n",
       "27722  SYMPHONY NO. 9, E MINOR, OP.95 (FROM THE NEW W...   \n",
       "27723  SYMPHONY NO. 9, E MINOR, OP.95 (FROM THE NEW W...   \n",
       "27724  SYMPHONY NO. 9, E MINOR, OP.95 (FROM THE NEW W...   \n",
       "\n",
       "                                              Movement         ConductorName  \\\n",
       "0      \"Un bel dì vedremo,\" Cio-Cio-San (aria), Act II  Mitropoulos, Dimitri   \n",
       "1                    \"The Last Rose of Summer,\" (aria)  Mitropoulos, Dimitri   \n",
       "2                                   Allegro non troppo  Mitropoulos, Dimitri   \n",
       "3                            Scherzando: Allegro molto  Mitropoulos, Dimitri   \n",
       "4                                              Andante  Mitropoulos, Dimitri   \n",
       "...                                                ...                   ...   \n",
       "27720                              Là ci darem la mano                   NaN   \n",
       "27721                                  Mvt. I, Excerpt        Gersen, Joshua   \n",
       "27722                                 Mvt. II, Excerpt        Gersen, Joshua   \n",
       "27723                                Mvt. III, Excerpt        Gersen, Joshua   \n",
       "27724                                Allegro con fuoco        Gersen, Joshua   \n",
       "\n",
       "             SoloistName SoloistInstrument SoloistRole  \n",
       "0        Farrell, Eileen           Soprano           S  \n",
       "1        Farrell, Eileen           Soprano           S  \n",
       "2          Renardy, Ossy            Violin           S  \n",
       "3          Renardy, Ossy            Violin           S  \n",
       "4          Renardy, Ossy            Violin           S  \n",
       "...                  ...               ...         ...  \n",
       "27720  Spanjer, R. Allen       French Horn           A  \n",
       "27721         Xu, Weiqin          Baritone           S  \n",
       "27722         Xu, Weiqin          Baritone           S  \n",
       "27723         Xu, Weiqin          Baritone           S  \n",
       "27724         Xu, Weiqin          Baritone           S  \n",
       "\n",
       "[27725 rows x 18 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyp_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1d5094ff",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1c1ab0d912e615ca",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def append_date_features(df: pd.DataFrame):\n",
    "    df = df.copy()\n",
    "    # Use the chain method to create multiple datatime columns\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    #Year, Month, Day and Weekday\n",
    "    df = df.assign(\n",
    "        Year = pd.to_datetime(df['Date']).dt.year, \n",
    "        Month = pd.to_datetime(df['Date']).dt.month, \n",
    "        Day = pd.to_datetime(df['Date']).dt.day, \n",
    "        Weekday = pd.to_datetime(df['Date']).dt.dayofweek\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def append_composer_last_name(df: pd.DataFrame):\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    df = df.copy()\n",
    "    df['ComposerLastName'] = df['ComposerName'].apply(lambda fullname: fullname.split(',')[0].strip())\n",
    "    return df\n",
    "\n",
    "def preprocess_data(df: pd.DataFrame):\n",
    "    # You should follow these exact steps:\n",
    "    #   1 - Include some date features: Year, Month, Hour, Minute, Day and Weekday\n",
    "    #   2 - Create a new feature, ComposerLastName from ComposerName column. \n",
    "    #   3 - Filter out rows that have a location that appear is less than 10 times in the DataFrame.\n",
    "    #   4 - Drop ProgramID, ConcertID, WorkID, Season, Date, Time\n",
    "    #   \n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    df = (df\n",
    "            .pipe(append_date_features)\n",
    "            .pipe(append_composer_last_name)\n",
    "            .groupby('Location').filter(lambda x: x.shape[0] >= 10)\n",
    "            .drop(['ProgramID', 'ConcertID', 'WorkID', 'Season', 'Date', 'Time'], axis=1, errors='ignore')\n",
    "            )\n",
    "    return df\n",
    "\n",
    "\n",
    "nyp_preprocessed = preprocess_data(nyp_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ee21e1d5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9d9c75c48e4eaf63",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert nyp_preprocessed.shape == (27571, 18)\n",
    "assert set(nyp_preprocessed.columns) == {\n",
    "       'EventType', 'Location', 'Venue', 'Orchestra',\n",
    "       'ComposerName', 'WorkTitle', 'Movement', 'ConductorName', 'SoloistName',\n",
    "       'SoloistInstrument', 'SoloistRole', 'Year', 'Month', 'Day', 'Hour',\n",
    "       'Minute', 'Weekday', 'ComposerLastName'\n",
    "}\n",
    "assert nyp_preprocessed.groupby('Location').size().min() == 10\n",
    "assert nyp_preprocessed.ComposerLastName.value_counts().loc['Mozart'] == 512\n",
    "assert nyp_preprocessed.ComposerLastName.value_counts().loc['Gershwin'] == 1673\n",
    "assert nyp_preprocessed.ComposerLastName.nunique() == 236"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4918d1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4557c57da6142038",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# The house prices dataset\n",
    "\n",
    "A dataset containing several characteristics of several houses and their selling price \n",
    "\n",
    "* LotFrontage: Linear feet of street connected to property\n",
    "* LotArea: Lot size in square feet\n",
    "* OverallQual: Rates the overall material and finish of the house\n",
    "       10  Very Excellent\n",
    "       9\tExcellent\n",
    "       8\tVery Good\n",
    "       7\tGood\n",
    "       6\tAbove Average\n",
    "       5\tAverage\n",
    "       4\tBelow Average\n",
    "       3\tFair\n",
    "       2\tPoor\n",
    "       1\tVery Poor\n",
    "* OverallCond: Rates the overall condition of the house\n",
    "\n",
    "       10\tVery Excellent\n",
    "       9\tExcellent\n",
    "       8\tVery Good\n",
    "       7\tGood\n",
    "       6\tAbove Average\t\n",
    "       5\tAverage\n",
    "       4\tBelow Average\t\n",
    "       3\tFair\n",
    "       2\tPoor\n",
    "       1\tVery Poor\n",
    "* MasVnrArea: Masonry veneer area in square feet\n",
    "* BsmtFinSF1: Type 1 finished square feet\n",
    "* BsmtUnfSF: Unfinished square feet of basement area\n",
    "* TotalBsmtSF: Total square feet of basement area\n",
    "* 1stFlrSF: First Floor square feet\n",
    "* 2ndFlrSF: Second floor square feet\n",
    "* LowQualFinSF: Low quality finished square feet (all floors)\n",
    "* GrLivArea: Above grade (ground) living area square feet\n",
    "* BsmtFullBath: Basement full bathrooms\n",
    "* BsmtHalfBath: Basement half bathrooms\n",
    "* FullBath: Full bathrooms above grade\n",
    "* HalfBath: Half baths above grade\n",
    "* BedroomAbvGr: Bedrooms above grade (does NOT include basement bedrooms)\n",
    "* KitchenAbvGr: Kitchens above grade\n",
    "* TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n",
    "* Fireplaces: Number of fireplaces\n",
    "* GarageCars: Size of garage in car capacity\n",
    "* GarageArea: Size of garage in square feet\n",
    "* WoodDeckSF: Wood deck area in square feet\n",
    "* OpenPorchSF: Open porch area in square feet\n",
    "* EnclosedPorch: Enclosed porch area in square feet\n",
    "* 3SsnPorch: Three season porch area in square feet\n",
    "* ScreenPorch: Screen porch area in square feet\n",
    "* PoolArea: Pool area in square feet\n",
    "* MiscVal: $Value of miscellaneous feature \n",
    "* SellingDate: Date when the house was sold\n",
    "* BuildingDate: Date when the house was built\n",
    "* RemodAddDate: Remodel date (same as construction date if no remodeling or additions)\n",
    "* SalePrice: The house price at the selling date (our target variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efd8c63",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2f274d778f5887e9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's read the csv and create our train-test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "049fd662",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7582e93ac7adb85f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def house_price_dataset():\n",
    "    return pd.read_csv(\n",
    "    'data/housePrices.csv', \n",
    "        parse_dates=[\n",
    "            'SellingDate',\n",
    "            'BuildingDate',\n",
    "            'RemodAddDate'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "dataset = house_price_dataset()\n",
    "dataset_train, dataset_test = train_test_split(dataset, random_state=0)\n",
    "X_train = dataset_train.drop(columns='SalePrice')\n",
    "y_train = dataset_train.SalePrice\n",
    "X_test = dataset_test.drop(columns='SalePrice')\n",
    "y_test = dataset_test.SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fa1fe4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-425695b0c9d45ae9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 8 Build a DateTransformer transformer (graded)\n",
    "\n",
    "There's a simple transformer that can be useful, from times to times, when modeling.\n",
    "\n",
    "What we want is to build a transformer that transforms dates into timedeltas.\n",
    "\n",
    "Usually when you have features that are Dates you compute a time delta between the feature and a given refence date.\n",
    "\n",
    "e.g Imagine that your clients have a loyalty period that ends at a given date. When your model is doing some predictions, one of the features that you can use is the number of days until the end of the loyalty period. i.e the date when the loyalty ends minus the date when your model is running. \n",
    "\n",
    "In the house prices dataset, the selling date will be the reference data, since we want to predict the house price at the selling date. For instance, two houses with the exact same features can vary in prices if the construction year is different. So we should input this information and feed into the model. Then we need to convert the other dates using our transformer\n",
    "\n",
    "Hint: Result should be integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "43b78c45",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d9538038181ba578",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "class DateTransformer(BaseEstimator, TransformerMixin):\n",
    "    # Implement the __init__ method.\n",
    "    # Our DateTransformer must be able to receive two parameters: \n",
    "    # datetime_cols: a list, that contains the datetime cols that should be converted\n",
    "    # ref_date_col - indicates the name of the column that should be used as reference date,\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    def __init__(self, datetime_cols: List[str], ref_date_col: str) -> None:\n",
    "        self.datetime_cols = datetime_cols\n",
    "        self.ref_date_col = ref_date_col\n",
    "        \n",
    "        \n",
    "    # There's no need for a fit method in this case, it does nothing.\n",
    "    # We should be able to call fit without any explicit parameters.\n",
    "    # Meaning: we should be able to call transformer.fit().\n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    def fit(self, X: pd.DataFrame, y=None)-> None:\n",
    "        return self\n",
    "\n",
    "    # Transform should transform all datetime columns into the difference in days to the reference date.\n",
    "    # The reference date column should be dropped. \n",
    "    # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        X = X.copy()\n",
    "        for datetime_col in self.datetime_cols:\n",
    "            X[datetime_col] = (pd.to_datetime(X[datetime_col]) - pd.to_datetime(X[self.ref_date_col])).dt.days.astype(int)\n",
    "        return X.drop(self.ref_date_col, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "bab1d26c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-b64b26753ecd8561",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_train_transformed = DateTransformer(\n",
    "    datetime_cols=['BuildingDate', 'RemodAddDate'], \n",
    "    ref_date_col='SellingDate'\n",
    ").fit_transform(X_train)\n",
    "assert X_train_transformed.BuildingDate.min() == -49008\n",
    "assert X_train_transformed.BuildingDate.max() == -1\n",
    "assert 'SellingDate' not in X_train_transformed.columns\n",
    "assert X_train_transformed.dtypes.BuildingDate == np.dtype('int64')\n",
    "assert X_train_transformed.dtypes.RemodAddDate == np.dtype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dc7b15",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5989c2b51d38b449",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You might be wondering why we have to implement it as a Transformer Class, and not using functions.\n",
    "You'll understand the reason in the next section - so we can tie them all together in a `Pipeline`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714780de",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-46fe8c71f80d2717",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 9 Building the pipeline (graded)\n",
    "\n",
    "Finally, we want to use the two transformers together and run a linear regression on top.\n",
    "\n",
    "We want to Convert the dates to time deltas relative to the Selling Date.\n",
    "\n",
    "We want to scale all features to the same range, using `sklearn.preprocessing.StandardScaler()`.\n",
    "\n",
    "We want to estimate the SellingPrice using a Liner Regression.\n",
    "\n",
    "Standardization of datasets is a common requirement for many machine learning estimators implemented in scikit-learn; they might behave badly if the individual features do not more or less look like standard normally distributed data: Gaussian with zero mean and unit variance.\n",
    "\n",
    "In practice we often ignore the shape of the distribution and just transform the data to center it by removing the mean value of each feature, then scale it by dividing non-constant features by their standard deviation.\n",
    "\n",
    "For instance, many elements used in the objective function of a learning algorithm (such as the RBF kernel of Support Vector Machines or the l1 and l2 regularizers of linear models) assume that all features are centered around zero and have variance in the same order. If a feature has a variance that is orders of magnitude larger than others, it might dominate the objective function and make the estimator unable to learn from other features correctly as expected.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697faf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ec0afe11",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6bc09de5e71383d3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 20737.060193147467\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline including:\n",
    "#   1 - 'date_converter', DateTransformer(['BuildingDate', 'RemodAddDate'], ref_date_col='SellingDate')\n",
    "#   2 - 'standard_scaler', StandardScaler() with the default parameters\n",
    "#   3 - 'model', LinearRegression\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "pipeline = Pipeline(\n",
    "        [\n",
    "        ('date_converter', DateTransformer(datetime_cols=['BuildingDate', 'RemodAddDate'], ref_date_col='SellingDate')),\n",
    "        ('robust_scaler', RobustScaler()),\n",
    "        ('model', LinearRegression())\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('MAE: {}'.format(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "01715551",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5d21dcdd34a13d24",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert type(pipeline) == Pipeline\n",
    "assert type(pipeline.named_steps['date_converter']) == DateTransformer\n",
    "assert type(pipeline.named_steps['robust_scaler']) == RobustScaler\n",
    "assert pipeline.named_steps['date_converter'].get_params()['ref_date_col'] == 'SellingDate'\n",
    "assert set(\n",
    "    pipeline.named_steps['date_converter'].get_params()['datetime_cols']\n",
    ") == {'BuildingDate', 'RemodAddDate'}\n",
    "assert type(pipeline.named_steps['model']) == LinearRegression "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97367e2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-154280375c499868",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 10. Access the cofficients from the pipeline (ungraded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0f0738",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9a913e812dcb37ff",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now we would want to obtain the coefficients from the model to understand features with the most predictive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "6404b9be",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-58083ef8ab8d97c7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#coefs = ....\n",
    "# YOUR CODE HERE\n",
    "coefs = pipeline.named_steps['model'].coef_\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "8810e2d4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f42cbedb988b6aa8",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert coefs.shape == (30,), 'Wrong number of coefficients. Did you select the features correctly?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3facfa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-57f2ca220627e218",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Exercises complete, congratulations! You are about to become a certified data wrangler."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('BLU02')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "be959f3e494a6288bd19fa1fcd896f9bc0f6f332980daac3c2fe6da31f3a8ece"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
